{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; color: purple;\" markdown=\"1\">Econ 320 Python Assignment 5  </h1>\n",
    "\n",
    "<h2 style=\"text-align: center; color: #012169\" markdown=\"1\">Regressions with Qualitative Information </h2>\n",
    "\n",
    "<h2 style=\"text-align: center; color: #012169\" markdown=\"1\">Yuritzy Ramos </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages \n",
    "\n",
    "import scipy.stats as stats\n",
    "from stargazer.stargazer import Stargazer\n",
    "from IPython.core.display import HTML\n",
    "import wooldridge as woo\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api  as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using the data wage2 from the wooldridge package. Estimate the models: m1, m2, m3, m4 \n",
    "\n",
    "Model 1 $$log(wage) = \\beta_0 + \\beta_1 educ + \\beta_2 exper + \\beta_3tenure + \\beta_4 married + u $$\n",
    "Model 2  $$log(wage) = \\beta_0 + \\beta_1 educ + \\beta_2 exper + \\beta_3tenure + \\beta_4 married + \\beta_5 black + u $$\n",
    "Model 3  $$log(wage) = \\beta_0 + \\beta_1 educ + \\beta_2 exper + \\beta_3tenure + \\beta_4 married + \\beta_5 black + \\beta_6 south + u $$ \n",
    "Model 4  $$log(wage) = \\beta_0 + \\beta_1 educ + \\beta_2 exper + \\beta_3tenure + \\beta_4 married + \\beta_5 black + \\beta_6 south + \\beta_7 urban + u$$ \n",
    "\n",
    "Report the results using a stargazer table. Holding other factors fixed, what is the aproximate difference in monthly salary between blacks vs non blacks, married vs single,  and urban vs rural?  Are these statistically significant? INTERPRET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "wage2 = woo.dataWoo('wage2')\n",
    "# set each regression\n",
    "m1 = smf.ols('np.log(wage) ~ educ + exper + tenure + married', data = wage2).fit()\n",
    "m2 = smf.ols('np.log(wage) ~ educ + exper + tenure + married + black', data = wage2).fit()\n",
    "m3 = smf.ols('np.log(wage) ~ educ + exper + tenure + married + black + south', data = wage2).fit()\n",
    "m4 = smf.ols('np.log(wage) ~ educ + exper + tenure + married + black + south + urban', data = wage2).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"4\"><em>Dependent variable:np.log(wage)</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td></tr><tr><td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">Intercept</td><td>5.331<sup>***</sup></td><td>5.451<sup>***</sup></td><td>5.505<sup>***</sup></td><td>5.395<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.114)</td><td>(0.115)</td><td>(0.115)</td><td>(0.113)</td></tr><tr><td style=\"text-align:left\">black</td><td></td><td>-0.197<sup>***</sup></td><td>-0.161<sup>***</sup></td><td>-0.188<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td></td><td>(0.038)</td><td>(0.038)</td><td>(0.038)</td></tr><tr><td style=\"text-align:left\">educ</td><td>0.075<sup>***</sup></td><td>0.070<sup>***</sup></td><td>0.068<sup>***</sup></td><td>0.065<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.006)</td><td>(0.006)</td><td>(0.006)</td><td>(0.006)</td></tr><tr><td style=\"text-align:left\">exper</td><td>0.014<sup>***</sup></td><td>0.014<sup>***</sup></td><td>0.014<sup>***</sup></td><td>0.014<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.003)</td><td>(0.003)</td><td>(0.003)</td><td>(0.003)</td></tr><tr><td style=\"text-align:left\">married</td><td>0.199<sup>***</sup></td><td>0.187<sup>***</sup></td><td>0.193<sup>***</sup></td><td>0.199<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.041)</td><td>(0.040)</td><td>(0.040)</td><td>(0.039)</td></tr><tr><td style=\"text-align:left\">south</td><td></td><td></td><td>-0.114<sup>***</sup></td><td>-0.091<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.027)</td><td>(0.026)</td></tr><tr><td style=\"text-align:left\">tenure</td><td>0.013<sup>***</sup></td><td>0.012<sup>***</sup></td><td>0.011<sup>***</sup></td><td>0.012<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.003)</td><td>(0.003)</td><td>(0.003)</td><td>(0.002)</td></tr><tr><td style=\"text-align:left\">urban</td><td></td><td></td><td></td><td>0.184<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td>(0.027)</td></tr><td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>935</td><td>935</td><td>935</td><td>935</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.176</td><td>0.200</td><td>0.215</td><td>0.253</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.173</td><td>0.195</td><td>0.210</td><td>0.247</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.383 (df=930)</td><td>0.378 (df=929)</td><td>0.374 (df=928)</td><td>0.365 (df=927)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>49.729<sup>***</sup> (df=4; 930)</td><td>46.354<sup>***</sup> (df=5; 929)</td><td>42.369<sup>***</sup> (df=6; 928)</td><td>44.747<sup>***</sup> (df=7; 927)</td></tr><tr><td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"4\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the results using a stargazer table\n",
    "\n",
    "st=Stargazer([m1,m2,m3,m4])\n",
    "from IPython.core.display import HTML\n",
    "HTML(st.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using model 4, add the variables $exper^2$ and $tenure^2$ to the equation show the regression results and test if they are jointly significant at 20% level. What about 25% Level? Explain.\n",
    "\n",
    "### Explanation: The fpval is approximately .23; therefore, $exper^2$ and $tenure^2$ are jointly significant at the 25% level becuase .23 < .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>np.log(wage)</td>   <th>  R-squared:         </th> <td>   0.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   35.17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 22 Nov 2021</td> <th>  Prob (F-statistic):</th> <td>1.22e-53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:46:37</td>     <th>  Log-Likelihood:    </th> <td> -380.05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   935</td>      <th>  AIC:               </th> <td>   780.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   925</td>      <th>  BIC:               </th> <td>   828.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>    5.3587</td> <td>    0.126</td> <td>   42.558</td> <td> 0.000</td> <td>    5.112</td> <td>    5.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>           <td>    0.0643</td> <td>    0.006</td> <td>   10.184</td> <td> 0.000</td> <td>    0.052</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>          <td>    0.0172</td> <td>    0.013</td> <td>    1.365</td> <td> 0.173</td> <td>   -0.008</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(exper ** 2)</th>  <td>   -0.0001</td> <td>    0.001</td> <td>   -0.214</td> <td> 0.831</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>         <td>    0.0249</td> <td>    0.008</td> <td>    3.066</td> <td> 0.002</td> <td>    0.009</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(tenure ** 2)</th> <td>   -0.0008</td> <td>    0.000</td> <td>   -1.691</td> <td> 0.091</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married</th>        <td>    0.1985</td> <td>    0.039</td> <td>    5.077</td> <td> 0.000</td> <td>    0.122</td> <td>    0.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>          <td>   -0.1907</td> <td>    0.038</td> <td>   -5.057</td> <td> 0.000</td> <td>   -0.265</td> <td>   -0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>south</th>          <td>   -0.0912</td> <td>    0.026</td> <td>   -3.477</td> <td> 0.001</td> <td>   -0.143</td> <td>   -0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>urban</th>          <td>    0.1854</td> <td>    0.027</td> <td>    6.878</td> <td> 0.000</td> <td>    0.133</td> <td>    0.238</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>37.281</td> <th>  Durbin-Watson:     </th> <td>   1.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  84.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.199</td> <th>  Prob(JB):          </th> <td>4.90e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.416</td> <th>  Cond. No.          </th> <td>2.19e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.19e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           np.log(wage)   R-squared:                       0.255\n",
       "Model:                            OLS   Adj. R-squared:                  0.248\n",
       "Method:                 Least Squares   F-statistic:                     35.17\n",
       "Date:                Mon, 22 Nov 2021   Prob (F-statistic):           1.22e-53\n",
       "Time:                        19:46:37   Log-Likelihood:                -380.05\n",
       "No. Observations:                 935   AIC:                             780.1\n",
       "Df Residuals:                     925   BIC:                             828.5\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept          5.3587      0.126     42.558      0.000       5.112       5.606\n",
       "educ               0.0643      0.006     10.184      0.000       0.052       0.077\n",
       "exper              0.0172      0.013      1.365      0.173      -0.008       0.042\n",
       "I(exper ** 2)     -0.0001      0.001     -0.214      0.831      -0.001       0.001\n",
       "tenure             0.0249      0.008      3.066      0.002       0.009       0.041\n",
       "I(tenure ** 2)    -0.0008      0.000     -1.691      0.091      -0.002       0.000\n",
       "married            0.1985      0.039      5.077      0.000       0.122       0.275\n",
       "black             -0.1907      0.038     -5.057      0.000      -0.265      -0.117\n",
       "south             -0.0912      0.026     -3.477      0.001      -0.143      -0.040\n",
       "urban              0.1854      0.027      6.878      0.000       0.133       0.238\n",
       "==============================================================================\n",
       "Omnibus:                       37.281   Durbin-Watson:                   1.819\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               84.322\n",
       "Skew:                          -0.199   Prob(JB):                     4.90e-19\n",
       "Kurtosis:                       4.416   Cond. No.                     2.19e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.19e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5= smf.ols('np.log(wage) ~ educ + exper + I(exper ** 2) +  tenure + I(tenure ** 2) + married + black + south + urban', data = wage2).fit()\n",
    "m5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fstat: 1.4898059755283246\n",
      "\n",
      "fpval: 0.2259567583278024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#vector with the names of the variables that you are testing \n",
    "hypotheses = ['I(exper ** 2) = 0','I(tenure ** 2) = 0']\n",
    "              \n",
    "#automated F test:\n",
    "ftest = m5.f_test(hypotheses)\n",
    "fstat = ftest.statistic[0][0]\n",
    "fpval = ftest.pvalue\n",
    "\n",
    "print(f'fstat: {fstat}\\n')\n",
    "print(f'fpval: {fpval}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using model 4 run model 6 by adding a dummy variable for age groups less than or equal to 30, between 30 to 35, older than 35. \n",
    "  - Do a frequency table using `pd.crosstab` showing the distribution of each group.  \n",
    "  - Make older than 35 the reference group, then run a regression. What can you say about the effect of age group on the wages? \n",
    "  - Show the regression results.\n",
    "  - make an anova table for the F test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq: \n",
      "col_0            count\n",
      "agegr                 \n",
      "Younger than 30    251\n",
      "30-34              408\n",
      "35 and up          276\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>np.log(wage)</td>   <th>  R-squared:         </th> <td>   0.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   35.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 22 Nov 2021</td> <th>  Prob (F-statistic):</th> <td>5.39e-54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:33:41</td>     <th>  Log-Likelihood:    </th> <td> -379.20</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   935</td>      <th>  AIC:               </th> <td>   778.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   925</td>      <th>  BIC:               </th> <td>   826.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                           <td></td>                              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                           <td>    5.5328</td> <td>    0.130</td> <td>   42.577</td> <td> 0.000</td> <td>    5.278</td> <td>    5.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(agegr, Treatment(\"35 and up\"))[T.Younger than 30]</th> <td>   -0.0803</td> <td>    0.037</td> <td>   -2.157</td> <td> 0.031</td> <td>   -0.153</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(agegr, Treatment(\"35 and up\"))[T.30-34]</th>           <td>   -0.0389</td> <td>    0.030</td> <td>   -1.278</td> <td> 0.202</td> <td>   -0.099</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>                                                <td>    0.0619</td> <td>    0.006</td> <td>    9.585</td> <td> 0.000</td> <td>    0.049</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>                                               <td>    0.0105</td> <td>    0.004</td> <td>    2.914</td> <td> 0.004</td> <td>    0.003</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>                                              <td>    0.0110</td> <td>    0.002</td> <td>    4.423</td> <td> 0.000</td> <td>    0.006</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married</th>                                             <td>    0.1951</td> <td>    0.039</td> <td>    4.994</td> <td> 0.000</td> <td>    0.118</td> <td>    0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>                                               <td>   -0.1883</td> <td>    0.038</td> <td>   -5.006</td> <td> 0.000</td> <td>   -0.262</td> <td>   -0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>south</th>                                               <td>   -0.0918</td> <td>    0.026</td> <td>   -3.500</td> <td> 0.000</td> <td>   -0.143</td> <td>   -0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>urban</th>                                               <td>    0.1835</td> <td>    0.027</td> <td>    6.807</td> <td> 0.000</td> <td>    0.131</td> <td>    0.236</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>38.035</td> <th>  Durbin-Watson:     </th> <td>   1.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  81.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.228</td> <th>  Prob(JB):          </th> <td>1.81e-18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.374</td> <th>  Cond. No.          </th> <td>    217.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           np.log(wage)   R-squared:                       0.256\n",
       "Model:                            OLS   Adj. R-squared:                  0.249\n",
       "Method:                 Least Squares   F-statistic:                     35.42\n",
       "Date:                Mon, 22 Nov 2021   Prob (F-statistic):           5.39e-54\n",
       "Time:                        18:33:41   Log-Likelihood:                -379.20\n",
       "No. Observations:                 935   AIC:                             778.4\n",
       "Df Residuals:                     925   BIC:                             826.8\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================================================\n",
       "                                                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                               5.5328      0.130     42.577      0.000       5.278       5.788\n",
       "C(agegr, Treatment(\"35 and up\"))[T.Younger than 30]    -0.0803      0.037     -2.157      0.031      -0.153      -0.007\n",
       "C(agegr, Treatment(\"35 and up\"))[T.30-34]              -0.0389      0.030     -1.278      0.202      -0.099       0.021\n",
       "educ                                                    0.0619      0.006      9.585      0.000       0.049       0.075\n",
       "exper                                                   0.0105      0.004      2.914      0.004       0.003       0.018\n",
       "tenure                                                  0.0110      0.002      4.423      0.000       0.006       0.016\n",
       "married                                                 0.1951      0.039      4.994      0.000       0.118       0.272\n",
       "black                                                  -0.1883      0.038     -5.006      0.000      -0.262      -0.114\n",
       "south                                                  -0.0918      0.026     -3.500      0.000      -0.143      -0.040\n",
       "urban                                                   0.1835      0.027      6.807      0.000       0.131       0.236\n",
       "==============================================================================\n",
       "Omnibus:                       38.035   Durbin-Watson:                   1.835\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               81.703\n",
       "Skew:                          -0.228   Prob(JB):                     1.81e-18\n",
       "Kurtosis:                       4.374   Cond. No.                         217.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "ageg = [0, 30, 35, 38]\n",
    "wage2['agegr'] = pd.cut(wage2[\"age\"], bins = ageg,\n",
    "                       labels=['Younger than 30', '30-34', '35 and up'])\n",
    "\n",
    "\n",
    "# display frequencies:\n",
    "freq = pd.crosstab(wage2[\"agegr\"],columns = 'count')\n",
    "print(f'freq: \\n{freq}\\n')\n",
    "\n",
    "# run regression:\n",
    "m6 = smf.ols(formula = 'np.log(wage) ~ C(agegr, Treatment(\"35 and up\")) + educ + exper + tenure + married + black + south + urban', data = wage2).fit()\n",
    "# print regression table:\n",
    "m6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_anova: \n",
      "                                      sum_sq     df          F        PR(>F)\n",
      "C(agegr, Treatment(\"35 and up\"))    0.619655    2.0   2.326242  9.823319e-02\n",
      "educ                               12.237293    1.0  91.879866  8.213351e-21\n",
      "exper                               1.130583    1.0   8.488627  3.659777e-03\n",
      "tenure                              2.604983    1.0  19.558694  1.091421e-05\n",
      "married                             3.321320    1.0  24.937089  7.078633e-07\n",
      "black                               3.337191    1.0  25.056252  6.665246e-07\n",
      "south                               1.631948    1.0  12.252966  4.866986e-04\n",
      "urban                               6.172039    1.0  46.340813  1.785375e-11\n",
      "Residual                          123.198870  925.0        NaN           NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ANOVA table:\n",
    "table_anova = sm.stats.anova_lm(m6, typ=2)\n",
    "print(f'table_anova: \\n{table_anova}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use model 4 but now allow wages to differ across four groups of people, married and black, married and nonblack, single and black and single and non black. Put the results in a stargarzer table. *(Hint: Think about how interactions work, what are all the categories in the interaction and what is the base category.) Do not create the interaction separately. Do it inside the `ols()` directly as learned in class. Interpret your result\n",
    "\n",
    "### Intrepretation: When individuals are black and single their wages decrease by 24.1 percent \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"3\"><em>Dependent variable:np.log(wage)</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">educ</td><td>0.065<sup>***</sup></td><td>0.065<sup>***</sup></td><td>0.065<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.006)</td><td>(0.006)</td><td>(0.006)</td></tr><tr><td style=\"text-align:left\">exper</td><td>0.014<sup>***</sup></td><td>0.014<sup>***</sup></td><td>0.014<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.003)</td><td>(0.003)</td><td>(0.003)</td></tr><tr><td style=\"text-align:left\">tenure</td><td>0.012<sup>***</sup></td><td>0.012<sup>***</sup></td><td>0.012<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.002)</td><td>(0.002)</td><td>(0.002)</td></tr><tr><td style=\"text-align:left\">south</td><td>-0.092<sup>***</sup></td><td>-0.092<sup>***</sup></td><td>-0.092<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.026)</td><td>(0.026)</td><td>(0.026)</td></tr><tr><td style=\"text-align:left\">urban</td><td>0.184<sup>***</sup></td><td>0.184<sup>***</sup></td><td>0.184<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.027)</td><td>(0.027)</td><td>(0.027)</td></tr><tr><td style=\"text-align:left\">married</td><td>0.189<sup>***</sup></td><td></td><td></td></tr><tr><td style=\"text-align:left\"></td><td>(0.043)</td><td></td><td></td></tr><tr><td style=\"text-align:left\">black</td><td>-0.241<sup>**</sup></td><td></td><td></td></tr><tr><td style=\"text-align:left\"></td><td>(0.096)</td><td></td><td></td></tr><tr><td style=\"text-align:left\">married:black</td><td>0.061<sup></sup></td><td></td><td></td></tr><tr><td style=\"text-align:left\"></td><td>(0.103)</td><td></td><td></td></tr><tr><td style=\"text-align:left\">marital_race[T.1_0]</td><td></td><td>0.189<sup>***</sup></td><td>0.189<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td></td><td>(0.043)</td><td>(0.043)</td></tr><tr><td style=\"text-align:left\">marital_race[T.0_1]</td><td></td><td>-0.241<sup>**</sup></td><td>-0.241<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td></td><td>(0.096)</td><td>(0.096)</td></tr><tr><td style=\"text-align:left\">marital_race[T.1_1]</td><td></td><td>0.009<sup></sup></td><td>0.009<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td></td><td>(0.056)</td><td>(0.056)</td></tr><tr><td style=\"text-align:left\">Intercept</td><td>5.404<sup>***</sup></td><td>5.404<sup>***</sup></td><td>5.404<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.114)</td><td>(0.114)</td><td>(0.114)</td></tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>935</td><td>935</td><td>935</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.253</td><td>0.253</td><td>0.253</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.246</td><td>0.246</td><td>0.246</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.366 (df=926)</td><td>0.366 (df=926)</td><td>0.366 (df=926)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>39.170<sup>***</sup> (df=8; 926)</td><td>39.170<sup>***</sup> (df=8; 926)</td><td>39.170<sup>***</sup> (df=8; 926)</td></tr><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"3\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "# - Option 1\n",
    "# As seen in class you can use the * function to create interactions of your dummy variables, \n",
    "# when using * you do not need to add the variables alone Phyton does that automatically for you. \n",
    "\n",
    "m7 = smf.ols('np.log(wage) ~ educ + exper + tenure + married*black + south + urban', data = wage2).fit()\n",
    "\n",
    "\n",
    "# # - Option 2\n",
    "# # The other way is using colon : for the interaction, \n",
    "# in which case you do need to add the main effects or main dummy variables, in this example, married and black. \n",
    "\n",
    "m8 = smf.ols('np.log(wage) ~ educ + exper + tenure + married + black + I(married*black) + south + urban', data = wage2).fit()\n",
    "\n",
    "# - Option 3\n",
    "# create the interaction factor variable before the regression, this creates four categories, married_black(00, 10, 01, 11)\n",
    "wage2['marital_race'] = wage2['married'].astype(int).astype('str')+'_'+wage2['black'].astype(int).astype('str')\n",
    "#wage2 = pd.get_dummies(wage2,columns=['marital_race']) # if you want to create the dummies separate\n",
    "m8 = smf.ols('np.log(wage) ~ educ + exper + tenure + marital_race + south + urban', data = wage2).fit()\n",
    "#view the results using a stargazer table\n",
    "\n",
    "st=Stargazer([m7,m8,m9])\n",
    "st.covariate_order(['educ', 'exper', 'tenure', 'south', 'urban', \n",
    "                    'married', 'black', 'married:black', 'marital_race[T.1_0]',\n",
    "                    'marital_race[T.0_1]','marital_race[T.1_1]','Intercept'])\n",
    "from IPython.core.display import HTML\n",
    "HTML(st.render_html())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Notice that**\n",
    " \n",
    "$\\beta_{married}+\\beta_{black}+\\beta_{married\\&black} =$ *Effect of being married and black vs single and non-black.*\n",
    "\n",
    "0.189+ -0.241+ 0.061 = 0.009 Same number for ùõΩùëöùëéùëüùëüùëñùëíùëë&ùëèùëôùëéùëêùëò "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "div.gray { background-color:#dbdbdb; border-radius: 5px; padding: 20px;}\n",
    "</style>\n",
    "<div class = \"gray\">\n",
    "\n",
    "**Packages used in this document**\n",
    "\n",
    "`wooldridge`\n",
    "`matplot.lib`\n",
    "`pandas`\n",
    "`numpy` \n",
    "`seaborn`\n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "<hr />\n",
    "<p style=\"font-family:palatino; text-align: center;font-size: 15px\">ECON220 Python Programming Laboratory</a></p>\n",
    "<p style=\"font-family:palatino; text-align: center;font-size: 15px\">Professor <em> Paloma Lopez de mesa Moyano</em></a></p>\n",
    "<p style=\"font-family:palatino; text-align: center;font-size: 15px\"><span style=\"color: #6666FF;\"><em>paloma.moyano@emory.edu</em></span></p>\n",
    "\n",
    "<p style=\"font-family:palatino; text-align: center;font-size: 15px\">Department of Economics</a></p>\n",
    "<p style=\"font-family:palatino; text-align: center; color: #012169;font-size: 15px\">Emory University</a></p>\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html Econ220Lab_Assign5_QualitativeVars.ipynb"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
